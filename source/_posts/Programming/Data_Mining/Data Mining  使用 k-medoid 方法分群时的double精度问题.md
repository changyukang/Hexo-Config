title: Data Mining:使用 k-medoid 方法分群时的double精度问题
layout: post
comment: true
date: 2019-03-16 03:11:03
categories: [Programming,Data_Mining]
tags: [Data_Mining]
keywords: double, precision, k-medoid
description: Data Mining:使用 k-medoid 方法分群时的double精度问题
---

# Data Mining:使用 k-medoid 方法分群时的double精度问题

## 1. 问题现象：使用k-medoid方法计算绝对误差标准 E时小数存在误差
根据计算公式，需要将每个 cluster 中的非中心点与该 cluster 的中心点进行距离计算，并将计算的结果累加；
这里的距离计算采用的是 Manhattan distance，数据是从分流后得到的 flow.txt 文档中读取的（文档中的数据确认正确，包含小数）；
之后从该文件读取小数，通过上面方式将绝对误差标准 E 求出来，输出精确到小数点后两位，问题出现在每次最后一位小数总会有不同程度的误差；

## 2. 问题确认
1. 检查文件读取到vector 数组中的小数是否正确，通过 cout 输出，两者没有差异；
2. 怀疑是计算 Manhattan distance 时，使用的绝对值函数有问题，尝试替换 fabs/fabsf/abs结果都一样，另外尝试判断小数大小，用大的减小的，结果仍有误差；
3. 怀疑分流后得到的数据有误差，尝试使用最初保存的流信息，也有误差，这些数据都打印出来检查过，没有看出异常；
4. 怀疑是不是结构体字节不对齐导致的，对结构体中的整型和 double 进行调整，甚至强制 1 字节对齐，仍然有误差；
5. 尝试不从 flow.txt 中读取数据，而是使用之前分流时的数据直接赋值过来，得到了正确结果；

## 3. 问题总结
1. 在生成流文件 flow.txt 时，小数存入文件进行了精度限制（setprecision（2）），所以相当于小数后面的精度被强制丢掉了；然后从 flow.txt 中读取小数时，读取的是精度丢失了的数据（个人认为，规则明确的情况下应该使用这个 flow.txt，毕竟生成了这个文件，就要以这个文件中的数据为准才对，但是问题结果中明显不是用的从 flow.txt 中读取的数据，这跟具体实现有关），这就导致了误差累积，最终的结果出现了偏差；
2. 在从 flow.txt 读取数据并打印出来是，使用的是 stod 对 string 进行的转换，这个过程中也可能存在误差，但是跟导致本问题不相关，记录下来以作备忘；比如：stod("-112.0707922")，最后得到的是-112.071，存在精度问题；本问题中数据文件 flow.txt 存储的小数虽然是精确到小数点后两位的，但是由于不同的小数在内存中分布不同，且没有规律可言，所以还是会存在精度问题；毕竟精度限制是在输出到文件或者终端时进行的，并不是在读取时进行的。
